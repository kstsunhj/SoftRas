{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tqdm\n",
    "import os\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_ids_map = {\n",
    "    '02691156': 'Airplane',\n",
    "    '02828884': 'Bench',\n",
    "    '02933112': 'Cabinet',\n",
    "    '02958343': 'Car',\n",
    "    '03001627': 'Chair',\n",
    "    '03211117': 'Display',\n",
    "    '03636649': 'Lamp',\n",
    "    '03691459': 'Loudspeaker',\n",
    "    '04090263': 'Rifle',\n",
    "    '04256520': 'Sofa',\n",
    "    '04379243': 'Table',\n",
    "    '04401088': 'Telephone',\n",
    "    '04530566': 'Watercraft',\n",
    "    '1':'',\n",
    "}\n",
    "class ShapeNet(object):\n",
    "    def __init__(self, directory=None, class_ids=None, set_name=None):\n",
    "        print(class_ids)\n",
    "        self.class_ids = class_ids\n",
    "        self.set_name = set_name\n",
    "        self.elevation = 30.\n",
    "        self.distance = 2.732\n",
    "\n",
    "        self.class_ids_map = class_ids_map\n",
    "\n",
    "        images = []\n",
    "        voxels = []\n",
    "        self.num_data = {}\n",
    "        self.pos = {}\n",
    "        count = 0\n",
    "        loop = tqdm.tqdm(self.class_ids)\n",
    "        #loop = self.class_ids\n",
    "        loop.set_description('Loading dataset')\n",
    "        for class_id in loop:\n",
    "            images.append(list(np.load(\n",
    "                os.path.join(directory, '%s_%s_images.npz' % (class_id, set_name))).items())[0][1])\n",
    "            voxels.append(list(np.load(\n",
    "                os.path.join(directory, '%s_%s_voxels.npz' % (class_id, set_name))).items())[0][1])\n",
    "            self.num_data[class_id] = images[-1].shape[0]\n",
    "            self.pos[class_id] = count\n",
    "            count += self.num_data[class_id]\n",
    "        images = np.concatenate(images, axis=0).reshape((-1, 4, 64, 64))\n",
    "        images = np.ascontiguousarray(images)\n",
    "        print(images.shape)\n",
    "        self.images = images\n",
    "        self.voxels = np.ascontiguousarray(np.concatenate(voxels, axis=0))\n",
    "        print(len(voxels[0]))\n",
    "        del images\n",
    "        del voxels\n",
    "\n",
    "    @property\n",
    "    def class_ids_pair(self):\n",
    "        class_names = [self.class_ids_map[i] for i in self.class_ids]\n",
    "        return zip(self.class_ids, class_names)\n",
    "    def get_all_batches_for_evaluation(self, batch_size, class_id):\n",
    "        data_ids = np.arange(self.num_data[class_id]) + self.pos[class_id]\n",
    "        viewpoint_ids = np.tile(np.arange(24), data_ids.size)\n",
    "        data_ids = np.repeat(data_ids, 24) * 24 + viewpoint_ids\n",
    "        print(data_ids)\n",
    "        for i in range((data_ids.size - 1) // batch_size + 1):\n",
    "            \n",
    "            images = torch.from_numpy(\n",
    "                self.images[data_ids[i * batch_size:(i + 1) * batch_size]].astype('float32') / 255.)\n",
    "            voxels = torch.from_numpy(\n",
    "                self.voxels[data_ids[i * batch_size:(i + 1) * batch_size] // 24].astype('float32'))\n",
    "            yield images, voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 1/1 [00:00<00:00, 393.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4, 64, 64)\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_test = ShapeNet(r'C:\\workspace\\SoftRas\\examples\\recon', {'1_1': ''}, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 1/1 [00:00<00:00, 199.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(1, 4, 64, 64)\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_val = ShapeNet(r'C:\\workspace\\SoftRas\\examples\\recon', '1', 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12844/739791718.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mclass_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataset_val\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_ids_pair\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_val\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_all_batches_for_evaluation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0mvoxels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    164\u001b[0m                 \"multiprocessing, you must use the 'spawn' start method\")\n\u001b[0;32m    165\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_cuda_getDeviceCount'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m             raise AssertionError(\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "for class_id, class_name in dataset_val.class_ids_pair:\n",
    "    for i, (im, vx) in enumerate(dataset_val.get_all_batches_for_evaluation(1, class_id)):\n",
    "        images = torch.autograd.Variable(im).cuda()\n",
    "        voxels = vx.numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a90aeebcf29d64a654773811cc170cb25061cb2498f10ac689db374c7bf325de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
